{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1024a1accbe2a69bedeb63b6393d999de7fefb22"
   },
   "source": [
    "## Exploratory Data Analysis is performed in the first part of this notebook.\n",
    "## Later RNN is used for classification of reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-487ac4583eca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mporter\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPorterStemmer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequence\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# Load Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "import nltk\n",
    "import nltk.classify.util\n",
    "from nltk.classify import NaiveBayesClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import statsmodels.api as sm\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.sentiment.util import *\n",
    "import re\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Flatten, Dense, SimpleRNN\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Womens Clothing E-Commerce Reviews.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "392416f2e90b7c24489df22914ed1f17b6aad59b"
   },
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d39085bd5dc99fbee4ee11edc368f70cf13532e6"
   },
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "4c6b2292af2b5e8bbcb9f4278adbe888c90107fc"
   },
   "source": [
    "# EDA - What can you Explore?\n",
    "- what age gives what type of rating?\n",
    "- What are recommended in each Division, Class, department of Clothes?\n",
    "- Which age group gives more comments/ratings on what type of clothes?\n",
    "- Rating vs Positive feedback count\n",
    "- Lengthy Reviews for what type of cloth?\n",
    "- Positive/Negative Reviews for what type of clothes?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bafded3b0ebc98c646c274f8a54338c67f68d065"
   },
   "source": [
    "## What age group has given what types of Ratings?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1f5d17f7b722c1a6b4b19d7f3acb3d997cd07538"
   },
   "outputs": [],
   "source": [
    "# The age distribution in data\n",
    "plt.hist(df['Age'], color=\"green\", label = \"Age\")\n",
    "plt.legend()\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Age Distribution in Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "28c511385dd840cd7c5978b105eadd0c09d18653"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(x = 'Rating', y = 'Age', data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "f15ae6fbe0b3dfa8ecf6f7d90dd4ac05121616d0"
   },
   "source": [
    "## What are Recommended Clothes item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "680e7a1dfef89ee8c465dfaabc0ecc254ff5b03e"
   },
   "outputs": [],
   "source": [
    "print(df['Division Name'].unique())\n",
    "print(df['Department Name'].unique())\n",
    "print(df['Class Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4faa8b762fb885e1220568a2ca4ddf4a6a64b8c1"
   },
   "outputs": [],
   "source": [
    "rd = df[df['Recommended IND'] == 1] # recommended\n",
    "nrd = df[df['Recommended IND'] == 0] # not recommended\n",
    "rd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b677a6f52a5372e79458a206dea42d5830d36ae9"
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "fig = plt.figure(figsize=(18, 18))\n",
    "ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "ax1 = plt.xticks(rotation=45)\n",
    "ax1 = plt.hist(rd['Division Name'], color = \"red\", alpha = 0.5, label = \"Recommended\")\n",
    "ax1 = plt.hist(nrd['Division Name'], color = \"blue\", alpha = 0.5, label = \"Not Recommended\")\n",
    "ax1 = plt.title(\"Recommended Items in each Division\")\n",
    "ax1 = plt.legend()\n",
    "\n",
    "ax2 = plt.subplot2grid((2, 2), (0, 1))\n",
    "ax2 = plt.xticks(rotation=45)\n",
    "ax2 = plt.hist(rd['Department Name'], color=\"green\", alpha = 0.5, label = \"Recommended\")\n",
    "ax2 = plt.hist(nrd['Department Name'], color=\"yellow\", alpha = 0.5, label = \"Not Recommended\")\n",
    "ax2 = plt.title(\"Recommended Items in each Department\")\n",
    "ax2 = plt.legend()\n",
    "\n",
    "ax3 = plt.subplot2grid((2, 2), (1, 0), colspan=2)\n",
    "ax3 = plt.xticks(rotation=45)\n",
    "ax3 = plt.hist(rd['Class Name'], color=\"blue\", alpha = 0.5, label = \"Recommended\")\n",
    "ax3 = plt.hist(nrd['Class Name'], color=\"cyan\", alpha = 0.5, label = \"Not Recommended\")\n",
    "ax3 = plt.title(\"Recommended Items in each Class\")\n",
    "ax3 = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "59f6dd8ae01fc65ded5c83a73a641eff0d9ec612"
   },
   "source": [
    "# Which age group gives what length of comments on what type of clothes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "2f008efed3e95557b375d823c93696ba417d117a"
   },
   "outputs": [],
   "source": [
    "df['Review Length'] = df['Review Text'].astype(str).apply(len)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3099c7fc339f7a98790728d13be389c4ec11b0e7"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10, 5))\n",
    "#ax1 = plt.hist(df['Review Length'], color = \"red\", bins = 20)\n",
    "ax = sns.distplot(df['Review Length'], color=\"blue\")\n",
    "ax = plt.title(\"Length of Reviews\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "38ed676c322519d5b1612641b11e998ebf5bc6b3"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "sns.boxplot(x = 'Age', y = 'Review Length', data = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6e77e0eb961a8f71e13d428114ac8fbe0e0331c7"
   },
   "outputs": [],
   "source": [
    "plt.style.use('ggplot')\n",
    "\n",
    "fig = plt.figure(figsize=(18, 18))\n",
    "ax1 = plt.subplot2grid((2, 2), (0, 0))\n",
    "ax1 = plt.xticks(rotation=45)\n",
    "ax1 = sns.boxplot(x = 'Division Name', y = 'Review Length', data = df)\n",
    "ax1 = plt.title(\"Review Length in each Division\")\n",
    "\n",
    "ax2 = plt.subplot2grid((2, 2), (0, 1))\n",
    "ax2 = plt.xticks(rotation=45)\n",
    "ax2 = sns.boxplot(x = 'Department Name', y = 'Review Length', data = df)\n",
    "ax2 = plt.title(\"Review Length in each Department\")\n",
    "\n",
    "ax3 = plt.subplot2grid((2, 2), (1, 0), colspan=2)\n",
    "ax3 = plt.xticks(rotation=45)\n",
    "ax3 = sns.boxplot(x = 'Class Name', y = 'Review Length', data = df)\n",
    "ax3 = plt.title(\"Review Length in each Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ae2d7145437032852809ae55d002e34701bb77b0"
   },
   "source": [
    "# Ratings vs. Positive Feedback Count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6344fb5b3535c8b290117f9766be9871bf6cb543"
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "sns.boxplot(x = 'Rating', y = 'Positive Feedback Count', data = df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "39b5611f18fb1337a0f847e48e4e043cc86aa026"
   },
   "source": [
    "# Review Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ec6fef295f3ad88aea214bce60f306d69bb6a551"
   },
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "Reviews = df['Review Text'].astype(str)\n",
    "print(Reviews.shape)\n",
    "Reviews[Reviews.isnull()] = \"NULL\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3cd14395acd12436dd5f8a4c50eb0541646fe65e"
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'[a-zA-Z]{3,}')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "def preprocessing(data):\n",
    "    txt = data.str.lower().str.cat(sep=' ') #1\n",
    "    words = tokenizer.tokenize(txt) #2\n",
    "    words = [w for w in words if not w in stop_words] #3\n",
    "    #words = [ps.stem(w) for w in words] #4\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "b79f5ead972d8ffcb20437984fd21533fbc751da"
   },
   "outputs": [],
   "source": [
    "df['tokenized'] = df[\"Review Text\"].astype(str).str.lower() # Turn into lower case text\n",
    "df['tokenized'] = df.apply(lambda row: tokenizer.tokenize(row['tokenized']), axis=1) # Apply tokenize to each row\n",
    "df['tokenized'] = df['tokenized'].apply(lambda x: [w for w in x if not w in stop_words]) # Remove stopwords from each row\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f05c910a067ef97477353fe95a48187515c50cd8"
   },
   "outputs": [],
   "source": [
    "def string_unlist(strlist):\n",
    "    return \" \".join(strlist)\n",
    "\n",
    "df[\"tokenized_unlist\"] = df[\"tokenized\"].apply(string_unlist)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "aea37c011971598decdfd4525fe8c531ecc844ac"
   },
   "source": [
    "### Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be913c79ab74df189416711459db91c55b26a536"
   },
   "outputs": [],
   "source": [
    "# Pre-Processing\n",
    "SIA = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Applying Model, Variable Creation\n",
    "df['Polarity Score']=df[\"tokenized_unlist\"].apply(lambda x:SIA.polarity_scores(x)['compound'])\n",
    "df['Neutral Score']=df[\"tokenized_unlist\"].apply(lambda x:SIA.polarity_scores(x)['neu'])\n",
    "df['Negative Score']=df[\"tokenized_unlist\"].apply(lambda x:SIA.polarity_scores(x)['neg'])\n",
    "df['Positive Score']=df[\"tokenized_unlist\"].apply(lambda x:SIA.polarity_scores(x)['pos'])\n",
    "\n",
    "# Converting 0 to 1 Decimal Score to a Categorical Variable\n",
    "df['Sentiment']=''\n",
    "df.loc[df['Polarity Score']>0,'Sentiment']='Positive'\n",
    "df.loc[df['Polarity Score']==0,'Sentiment']='Neutral'\n",
    "df.loc[df['Polarity Score']<0,'Sentiment']='Negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "be040446bd5e1966e3650bea2c5804254293273f"
   },
   "outputs": [],
   "source": [
    "conditions = [\n",
    "    df['Sentiment'] == \"Positive\",\n",
    "    df['Sentiment'] == \"Negative\",\n",
    "    df['Sentiment'] == \"Neutral\"]\n",
    "choices = [1,-1,0]\n",
    "df['label'] = np.select(conditions, choices)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ad4d01b881a01a0b14c9fc5d44bdb85a43cb89ef"
   },
   "source": [
    "### Simple Embedding Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9353dc83a7ca7f39003baf3e5cbdfee266ba0c88"
   },
   "outputs": [],
   "source": [
    "samples = df[\"tokenized_unlist\"].tolist()\n",
    "maxlen = 100 \n",
    "max_words = 10000\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(samples)\n",
    "sequences = tokenizer.texts_to_sequences(samples)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "data = pad_sequences(sequences, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bba99133ab92c23176957fc567eb7ddac9d9dd67"
   },
   "outputs": [],
   "source": [
    "labels = np.asarray(df[\"label\"].values)\n",
    "print('Shape of data tensor:', data.shape)\n",
    "print('Shape of label tensor:', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "da9e288f4765947a4f3c2fcf64d4aaf849dedf5b"
   },
   "outputs": [],
   "source": [
    "indices = np.arange(df.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "data = data[indices]\n",
    "labels = labels[indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ee8980bead6d5603dac7915fe872462e907400eb"
   },
   "outputs": [],
   "source": [
    "training_samples = 11743\n",
    "validation_samples = 17614\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: validation_samples] \n",
    "y_val = labels[training_samples: validation_samples]\n",
    "x_test = data[validation_samples:]\n",
    "y_test = labels[validation_samples:]\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "91c719a4eae05f22df56ea0ed589c2b88891f536"
   },
   "source": [
    "##### Baseline for Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e736de647d5b73938dfa121ce1a537d88da8e53e"
   },
   "outputs": [],
   "source": [
    "# BASELINE\n",
    "# That is, if all the labels are predicted as 1\n",
    "(np.sum(df['label'] == 1)/df.shape[0]) * 100\n",
    "\n",
    "# we have to make model that performs better than this baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "539b2b1b06b0ea5586accda00c76e646b5282cda"
   },
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Embedding(max_words, 100, input_length=maxlen))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "7144d65ed09590e11ed9f082a936a17206fa20e2"
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "model.save(\"model1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "64ade3c831c4aeecbf6fe22635e47abcb29827a8"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "f0420b7431e3d7a4a1b2d91edf2b675018ed0b6d"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "6aa02d337c1c5d9a82e691616f9338c925dac3b3"
   },
   "source": [
    "### RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "720c29f72c0348424b44b42c26f6d107189b1dc7"
   },
   "outputs": [],
   "source": [
    "def build_RNN():\n",
    "    model = Sequential() \n",
    "    model.add(Embedding(max_words, 100, input_length=maxlen)) \n",
    "    #model.add(SimpleRNN(32, return_sequences=True))\n",
    "    model.add(SimpleRNN(32)) \n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc']) \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "bb8a946a2b64e36550e8d4524f615bef6c538f0f"
   },
   "outputs": [],
   "source": [
    "model = build_RNN()\n",
    "model.summary()\n",
    "history_RNN = model.fit(x_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "model.save(\"model_RNN.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e8287abb312879636697336fc09545d9d7de5240"
   },
   "outputs": [],
   "source": [
    "acc = history_RNN.history['acc']\n",
    "val_acc = history_RNN.history['val_acc']\n",
    "loss = history_RNN.history['loss']\n",
    "val_loss = history_RNN.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "07864562b49b97803ddf0575c91193feb7fb0dac"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "1e9613e88db0e86052414958f536c2ec67445e1a"
   },
   "source": [
    "## Prediction of Recommended IND[](http://)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "095e5e087d1643dc1d5e69d5436debb3db2985e3"
   },
   "outputs": [],
   "source": [
    "# BASELINE\n",
    "# That is, if all the labels are predicted as 1\n",
    "(np.sum(df['Recommended IND'] == 1)/df.shape[0]) * 100\n",
    "\n",
    "# we have to make model that performs better than this baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "bb31d9b31654ad334c559ce81d51e6a549167e4d"
   },
   "source": [
    "### Naive Bayes Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45e7c1d79da709b3d4f109246fcf33b92c36a81f"
   },
   "outputs": [],
   "source": [
    "def create_dict(tokenized_list):\n",
    "    my_dict = dict([(word, True) for word in tokenized_list])\n",
    "    return my_dict\n",
    "df[\"NBCdata\"] = df[\"tokenized\"].apply(create_dict)\n",
    "r_data = df[\"NBCdata\"].values\n",
    "reviews_labels = df[\"Recommended IND\"].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "3745b81243cef6a7c7391b5f74de3c9eeed838d8"
   },
   "outputs": [],
   "source": [
    "reviews_data = []\n",
    "for i in range(len(r_data)):\n",
    "    reviews_data.append([r_data[i], reviews_labels[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ff411cd6fe138c80b7c386c3986dcd5cba15dcf7"
   },
   "outputs": [],
   "source": [
    "train_data = reviews_data[:18788]\n",
    "test_data = reviews_data[18788:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6964e460e7aedb41fbde44fafa42f8582cd40ccd"
   },
   "outputs": [],
   "source": [
    "classifier = NaiveBayesClassifier.train(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "c88bff38372f86d894f7f5713956d2a294cdfd12"
   },
   "outputs": [],
   "source": [
    "classifier.show_most_informative_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "8f86c7c40b8c0092ea3705ece9fc6582a2097812"
   },
   "outputs": [],
   "source": [
    "accuracy = nltk.classify.util.accuracy(classifier, test_data)\n",
    "print(\"Classification Accuracy for Recommendation is...\")\n",
    "print(accuracy * 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "086bbe10c2d577842b0ec45357280a56301d47ca",
    "collapsed": true
   },
   "source": [
    "### Deep Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a98a1db30fb1bef99526140df838d89c6c2b52e1"
   },
   "outputs": [],
   "source": [
    "# Deep learning models\n",
    "labels = np.asarray(df[\"Recommended IND\"].values)\n",
    "labels = labels[indices]\n",
    "x_train = data[:training_samples]\n",
    "y_train = labels[:training_samples]\n",
    "x_val = data[training_samples: validation_samples] \n",
    "y_val = labels[training_samples: validation_samples]\n",
    "x_test = data[validation_samples:]\n",
    "y_test = labels[validation_samples:]\n",
    "x_train = pad_sequences(x_train, maxlen=maxlen)\n",
    "x_val = pad_sequences(x_val, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "50bf951d6de78d4a18b6d722653470a64e8baaa7"
   },
   "outputs": [],
   "source": [
    "model = build_model()\n",
    "model.summary()\n",
    "history = model.fit(x_train, y_train,\n",
    "                    epochs=5,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "model.save(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "4db64e8f5f11a9f74c9e2fcc561b6b4571efd294"
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "45cc2e4b77a6d689244b84c4c833ef985301e07c"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "0021572116713b7e5aae7ebecf31a9ef385741d4"
   },
   "outputs": [],
   "source": [
    "model = build_RNN()\n",
    "model.summary()\n",
    "history_RNN = model.fit(x_train, y_train,\n",
    "                    epochs=2,\n",
    "                    batch_size=32,\n",
    "                    validation_data=(x_val, y_val))\n",
    "\n",
    "model.save(\"model_RNN2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "e5d35ea4a2e0f47c8f641f614455e6d8896d272d"
   },
   "outputs": [],
   "source": [
    "acc = history_RNN.history['acc']\n",
    "val_acc = history_RNN.history['val_acc']\n",
    "loss = history_RNN.history['loss']\n",
    "val_loss = history_RNN.history['val_loss']\n",
    "epochs = range(1, len(acc) + 1)\n",
    "plt.plot(epochs, acc, 'bo', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'bo', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "ed2dba1c3c65cfd424b76a601d59713aef3c6fda"
   },
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "9e756f2cf71025fc8e70eaab77dff567611b58a0"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
